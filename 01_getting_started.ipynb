{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083fa9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da96f0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000159D27555A0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000159D5041720> root_client=<openai.OpenAI object at 0x00000159D2755330> root_async_client=<openai.AsyncOpenAI object at 0x00000159D4B8E170> model_name='gpt-4o-mini' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98f2960a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Generative AI refers to a subset of artificial intelligence that focuses on creating new content, data, or information automatically. Unlike traditional AI systems that may analyze or categorize existing data, generative AI models are designed to generate original content, which can include text, images, music, and more.\\n\\nKey characteristics of generative AI include:\\n\\n1. **Learning from Data**: Generative AI models are typically trained on large datasets, allowing them to learn patterns, structures, and styles from the data.\\n\\n2. **Content Creation**: These models can produce a variety of outputs based on the learned information. For example, they can generate human-like text (as seen in models like GPT), create realistic images (like those produced by GANs - Generative Adversarial Networks), or compose music.\\n\\n3. **Applications**: Generative AI has a wide range of applications, including content generation for marketing, art creation, game design, personalized recommendations, chatbots, and more.\\n\\n4. **Demand for Creativity**: By mimicking human creativity, generative AI systems can assist or augment artistic and creative efforts across various fields.\\n\\nProminent examples of generative AI technologies include:\\n- **Language Models**: Such as OpenAI's GPT-3 and GPT-4, used for generating text, answering questions, and engaging in conversation.\\n- **Image Generators**: Like DALL-E and Midjourney, which create images from textual descriptions.\\n- **Music Generators**: Tools that compose original music based on input parameters or styles.\\n\\nGenerative AI continues to evolve, raising important discussions around ethics, copyright, authenticity, and the implications of creating content automatically.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 336, 'prompt_tokens': 13, 'total_tokens': 349, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'id': 'chatcmpl-BWYCB4ShIENnqk8sNReP8zM6SCQVP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--333fdb44-10ce-4e7f-a385-82139693aa0b-0', usage_metadata={'input_tokens': 13, 'output_tokens': 336, 'total_tokens': 349, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm.invoke(\"What is Generative AI?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b450e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a witty author.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat Prompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a witty author.\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1583e379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I'm doing wonderfully, thank you! Just here, ready to spin words into gold and craft tales as delicious as a freshly baked pie. How about you? Howâ€™s your day in the human realm?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 23, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BWYIYxJQ6TBrlAW3DJwUPeN0s93iv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--53e21542-4483-4330-806b-3c5fe30b0ea4-0' usage_metadata={'input_tokens': 23, 'output_tokens': 41, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|llm\n",
    "\n",
    "resp = chain.invoke({\"input\": \"How are you doing today?\"})\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7730893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9076863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm doing quite splendidly, thank you! Just another day in the digital realm, spinning words and dodging existential crises. How about you? Ready to tackle the day or just here for the snacks?\n"
     ]
    }
   ],
   "source": [
    "# String Output Parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "resp = chain.invoke({\"input\": \"How are you doing today?\"})\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39723f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65169ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a83360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f85da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad61424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
